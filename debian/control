Source: pxzgrep
Section: utils
Priority: optional
Maintainer: Axel Beckert <abe@debian.org>
Build-Depends: debhelper-compat (= 13),
               libtest-command-simple-perl <!nocheck>,
               libtest-differences-perl <!nocheck>,
               libtest-file-contents-perl <!nocheck>,
               perl,
               ronn (>= 0.9.0),
               xz-utils
Standards-Version: 4.6.2
Homepage: https://github.com/ETHZ-IT-SeC/pxzgrep#readme
Vcs-Browser: https://github.com/ETHZ-IT-SeC/pxzgrep
Vcs-Git: https://github.com/ETHZ-IT-SeC/pxzgrep.git
Rules-Requires-Root: no

Package: pxzgrep
Architecture: all
Depends: ${misc:Depends},
         xz-utils
Enhances: xz-utils
Description: parallel xzgrep wrapper, supports multiple compression formats
 If you need to grep through terabytes of compressed log files, this
 can take a lot of time if you do it serial - even on fast hardware.
 .
 But since such amounts of logs are usually not stored in a single
 file and most servers today have multiple cores anyway, you can get a
 massive speed up if you run multiple xzgrep processes in parallel,
 especially if the logs are on fast media like NVMe.
 .
 pxzgrep automates this.
 .
 Despite its (and xzgrep's) name, it does not only support the xz
 compression format but supports all compression formats xzgrep itself
 supports. As of now these are:
 .
  * .xz and .lzma
  * .gz (gzip)
  * .bz2 (bzip2)
  * .lzo (lzop)
  * .zstd (zstd)
  * .Z and .z (compress)
 .
 Due to its parallel approach it does NOT output the search result to
 STDOUT, but instead saves for every path to a compressed file it got
 on the commandline an uncompressed file of the same basename in the
 current working directory, i.e. the directory it was called from.
